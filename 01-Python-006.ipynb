{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# <span style=\"color:#0485CF\"> Pruebas unitarias: Fixtures\n",
    "\n",
    " - ### https://docs.pytest.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uso de Fixtures\n",
    "\n",
    "- ### Las fixtures son la forma en que nos preparamos para una prueba\n",
    "\n",
    "- ### Inicializa las funciones por probar\n",
    "\n",
    "- ### Proporcionan una línea de base fija para que las pruebas se ejecuten de manera confiable y produzcan resultados consistentes y repetibles. \n",
    "\n",
    "- ### La inicialización puede configurar servicios, estados u otros entornos operativos. \n",
    "\n",
    "- ### Las funciones de prueba acceden a estos a través de argumentos\n",
    "\n",
    "- ### Se definen con el decorador @pytest.fixture\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en el archivo test_calcular.py\n",
    "\n",
    "import pytest\n",
    "\n",
    "# Definir la función que queremos probar\n",
    "def calcular(a, b):\n",
    "    return a * b\n",
    "\n",
    "# Definir una fixture para proporcionar datos de prueba\n",
    "@pytest.fixture\n",
    "def input_values():\n",
    "    a = 5\n",
    "    b = 3\n",
    "    return a, b\n",
    "\n",
    "# Definir el caso de prueba que utiliza la fixture\n",
    "def test_calcular(input_values):\n",
    "    a, b = input_values\n",
    "    result = calcular(a, b)\n",
    "    assert result == 15  # Verificar que el resultado es el esperado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desde la terminal:\n",
    "### > pytest -v test_calcular.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# archivo: test_rectangulo.py\n",
    "\n",
    "import pytest\n",
    "\n",
    "class Rectangulo:\n",
    "    def __init__(self, base, altura):\n",
    "        self.base = base\n",
    "        self.altura = altura\n",
    "\n",
    "    def area(self):\n",
    "        return self.base * self.altura\n",
    "    \n",
    "\n",
    "@pytest.fixture\n",
    "def rectangulo():\n",
    "    # Esta fixture proporciona un rectángulo con base 3 y altura 4\n",
    "    return Rectangulo(3, 4)\n",
    "\n",
    "def test_area(rectangulo):\n",
    "    # Verifica si el área del rectángulo es 12 (3 * 4)\n",
    "    assert rectangulo.area() == 12\n",
    "\n",
    "def test_otra_area():\n",
    "    # También podemos usar la fixture sin pasarla explícitamente\n",
    "    otro_rectangulo = Rectangulo(5, 6)\n",
    "    assert otro_rectangulo.area() == 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desde la terminal:\n",
    "### > pytest -v test_rectangulo.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0485CF\"> Ejercicio: </span>\n",
    "\n",
    "### Crear las pruebas unitarias para las funciones:\n",
    "\n",
    "- ### Implementar las funciones calcular y la clase Rectangulo en  módulos independientes en el paquete mi_paquete. Agregar los tests al paquete de tests. Probar la ejecución de los test para calcular y la clase Rectangulo.\n",
    "\n",
    "\n",
    "- ### Agregar una función que calcule el área de un trángulo. Agregar las pruebas unitarias y demostrar el uso con la creación de un triángulo y el cálculo de su área. Considerar datos tanto válidos como inválidos, implementar los tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# <span style=\"color:#0485CF\"> Pruebas unitarias: Marcadores\n",
    "\n",
    " - ### https://docs.pytest.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uso de marcadores \n",
    "\n",
    "- ### Al utilizar pytest.mark, se puede  configurar metadatos en las funciones de prueba. \n",
    "\n",
    "- ### Los marcadores solo se pueden aplicar a los tests\n",
    "\n",
    "\n",
    "- ### Algunos marcadores:\n",
    "\n",
    "    - parametrize - realiza múltiples llamadas a la misma función de prueba.\n",
    "    - skip - omitir siempre una función de prueba\n",
    "    - skipif - omite una función de prueba si se cumple una determinada condición.\n",
    "    - xfail - produce un resultado de \"fallo esperado\" si se cumple una determinada condición​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contenido del archivo:  test_mark_users.py\n",
    "import pytest\n",
    "\n",
    "def get_user_info(user_id):\n",
    "\n",
    "    # Estos datos generalmente provienen de la Base de Datos o de una API\n",
    "    if user_id == 1:\n",
    "        return {'name': 'Luisa', 'age': 30}\n",
    "    elif user_id == 2:\n",
    "        return {'name': 'Pedro', 'age': 40}\n",
    "    elif user_id == 3:\n",
    "        return {'name': 'Juan', 'age': 50}\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "@pytest.mark.parametrize(\"user_id, expected_name, expected_age\", [\n",
    "    (1, 'Luisa', 30),\n",
    "    (2, 'Pedro', 40),\n",
    "    (3, 'Juan', 50),\n",
    "    (4, None, None),\n",
    "])\n",
    "\n",
    "def test_get_user_info(user_id, expected_name, expected_age):\n",
    "    user_info = get_user_info(user_id)\n",
    "    if user_info is None:\n",
    "        assert user_info == expected_name\n",
    "    else:\n",
    "        assert user_info['name'] == expected_name\n",
    "        assert user_info['age'] == expected_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desde la terminal:\n",
    "### > pytest -v test_mark_users.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0485CF\"> Ejercicio: </span>\n",
    "\n",
    "### Crear las pruebas unitarias para las:\n",
    "\n",
    "- ### Función que calcule el área de varios triángulos como parámetros (hacer uso de una clase Triangulo definida), al menos 4 elementos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0485CF\"> Ejercicio: </span>\n",
    "\n",
    "### Crear las pruebas unitarias para las funciones:\n",
    "\n",
    "- ### Función que calcule el factorial de un número y haga uso de varias pruebas como parámetros, al menos 4 elementos\n",
    "\n",
    "- ### Función que calcule el promedio de una lista de números y haga uso de varias pruebas como parámetros\n",
    "\n",
    "- ### Función que calcule el área de varios rectángulos como parámetros (hacer uso de la clase Rectangulo), al menos 4 elementos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# <span style=\"color:#0485CF\"> Marcador skip</span>\n",
    "\n",
    "\n",
    " - ### Un 'skip' significa que espera que la prueba pase solo si se cumplen algunas condiciones; de lo contrario, pytest debería omitir la ejecución de la prueba por completo.\n",
    "- ### Ejemplos:  \n",
    "    - #### Omitir pruebas solo de Windows en plataformas que no son de Windows \n",
    "    - #### Omitir pruebas que dependen de un recurso externo que no está disponible en este momento (por ejemplo, una base de datos)\n",
    " \n",
    "\n",
    " - ### https://docs.pytest.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.skip(reason=\"No se puede probar esto actualmente, BD en mantenimiento\")\n",
    "def test_conexion_BasePostSQL():\n",
    "     pass\n",
    "\n",
    "\n",
    "@pytest.mark.skip(reason=\"Solo soporte para Windows\")\n",
    "def test_consultar_REGEDIT():\n",
    "     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# <span style=\"color:#0485CF\"> Ejercicio </span>\n",
    "\n",
    "\n",
    " - ### Agregar los marcadores skip a un archivo test_marks_ejemplo1\n",
    " - ### Ejecutar el test\n",
    " - ### Agregar dos pruebas más que considere este marcador \n",
    "\n",
    "\n",
    "\n",
    " - ### https://docs.pytest.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# <span style=\"color:#0485CF\"> Marcador xfail</span>\n",
    "\n",
    "\n",
    " - ### Un xfail significa que espera que una prueba falle por algún motivo. \n",
    "- ### Ejemplo:  \n",
    "    - #### Una prueba de una función que aún no se ha implementado o de un error que aún no se ha solucionado. \n",
    "    - #### Cuando una prueba se supera a pesar de que se espera que falle (marcada con pytest.mark.xfail), es un xpass y se informará en el resumen de la prueba. \n",
    "\n",
    " - ### https://docs.pytest.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.xfail(reason=\"Se espera que fallé, no se ha implementado la funcionalidad\")\n",
    "def test_baja_usuario():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# <span style=\"color:#0485CF\"> Marcador skipif</span>\n",
    "\n",
    "\n",
    " - ### Si se desea omitir algo de forma condicional, se puede utilizar skipif. \n",
    "- ### Ejemplo:  \n",
    "    - #### Cómo marcar una función de prueba para omitirla cuando se ejecuta en un intérprete anterior a Python 3.10:\n",
    "\n",
    " - ### https://docs.pytest.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sys.version_info(major=3, minor=12, micro=1, releaselevel='final', serial=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@pytest.mark.skipif(sys.version_info > (3, 10), reason=\"requiere Python 3.10 o menor\")\n",
    "def test_function_version():\n",
    "    assert 0 == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# <span style=\"color:#0485CF\"> Pruebas unitarias: pytest, agrupando múltiples tests</span>\n",
    "\n",
    "\n",
    " - ### Por convención pytest busca funciones con el prefijo \"test\"\n",
    " \n",
    " - ### Las clases deben tener el prefijo \"Test\", de lo contrario la clase no se ejecutará \n",
    "\n",
    "\n",
    " - ### https://docs.pytest.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creando la clase TestEjemplo1.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear el archivo test_clase_ejemplo1.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contenido test_clase_ejemplo1.py\n",
    "\n",
    "class TestEjemplo1:\n",
    "    def test_ejem1(self):\n",
    "        x = \"hola\"\n",
    "        assert \"h\" in x\n",
    "\n",
    "    def test_ejem2(self):\n",
    "        x = \"hello\"\n",
    "        assert isinstance(x, str) # revisa si el objeto es instancia de el tipo de dato srt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecución del test, desde la terminal\n",
    "\n",
    "### pytest test_clase_ejemplo1.py\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0485CF\"> Ejercicio: </span>\n",
    "\n",
    "### Crear una clase de  pruebas unitarias que integre el diseño de pruebas\n",
    "\n",
    "- ### El test que simule la comprobación de una función que no ha sido implementada de consulta de saldo.\n",
    "\n",
    "- ### El test que simule la consulta de datos en una función que no ha sido implementada, que tiene como parámetros de entrada y salida (RFC, expected_nombre), cree almenos 3 entradas de datos como parámetros.\n",
    "\n",
    "- ### El test que simule la comprobación de una función que el recurso no se encuentra disponible por problemas de integración de sistemas (REPUVE), que tiene como parámetros (PLACA, expected_dict_datos_vehiculo), cree almenos 3 entradas de datos como parámetros. Datos del vehículo: Marca, Color, y  Modelo, representados en un diccionario o como parámetros independientes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0485CF\"> Ejercicio: </span>\n",
    "\n",
    "### Crear una clase de  pruebas unitarias que integre\n",
    "\n",
    "- ### El test para la función factorial, al menos 4 elementos.\n",
    "\n",
    "- ### El test para la comprobación del área de múltiples rectángulos, al menos 4 elementos.\n",
    "\n",
    "- ### El test para la comprobación el promedio de una lista de números, al menos 4 listas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PostSQL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
